{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8章　勾配降下法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 勾配降下法の考え方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.linear_algebra import Vector, dot\n",
    "\n",
    "def sum_of_squares(v: Vector) -> float:\n",
    "    \"\"\"\n",
    "    二乗和\n",
    "    \"\"\"\n",
    "    return dot(v, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum_of_squares(v:Vector)は実数ベクトルを受け取り、１つ実数を返す簡単な関数。\n",
    "最適化はこのような関数から最大（または最小）の出力をもたらすvを見つけ出すこと。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 勾配の評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "# 差分商？を返す？\n",
    "def difference_quotient(f: Callable[[float], float],\n",
    "                       x: float,\n",
    "                       h: float) -> float:\n",
    "    return (f(x + h) - f(x)) / h\n",
    "\n",
    "# 仮引数fは関数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "導関数は「値を入力したらその値における微分係数を返す関数」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二乗する関数square\n",
    "\n",
    "def square(x: float ) -> float:\n",
    "    return x * x\n",
    "\n",
    "# squareの導関数は\n",
    "# (x ^ n)' が nx ^ (n-1)　なので\n",
    "def derivative(x: float) -> float:\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非常に小さな値hで差分商を計算することで微分係数をもとめてみる\n",
    "\n",
    "xs = range(-10, 11)\n",
    "actuals = [derivative(x) for x in xs]\n",
    "estimates = [difference_quotient(square, x, h=0.01) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# プロットする。導関数に値を代入した実際値と、hを非常に小さくした差分商から得た推定値はほぼ同じ値\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"Actual Derivatives vs. Estimates\")\n",
    "plt.plot(xs, actuals, 'rx', label='Actual')\n",
    "plt.plot(xs, estimates, 'b+', label='Estimate')\n",
    "plt.legend(loc=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fが多変数関数であった場合偏導関数は複数存在する。それぞれの偏導関数は対応するそれぞれの変数を微小に変化させた際にfがどの程度変化するかを表す。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i番目の変数以外を固定し変数の関数として扱うことで、i番目の偏導関数を計算する\n",
    "\n",
    "def partial_difference_quotient(f: Callable[[Vector], float],\n",
    "                                v: Vector,\n",
    "                                i: int, \n",
    "                                h: float) -> float:\n",
    "    w = [v_j + (h if j == i else 0)\n",
    "        for i, v_j in enumerate(v)]\n",
    "    return (f(w) - f(v)) /h\n",
    "\n",
    "# 同様に勾配を求める\n",
    "def estimate_gradient(f: Callable[[Vector], float],\n",
    "                      v: Vector,\n",
    "                      h: float = 0.0001):\n",
    "    return [partial_difference_quotient(f, v, i, h)\n",
    "           for i in range(len(v))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 勾配を利用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_of_squares関数が最小になるのは入力vが0のベクトルである場合だが、それを知らないこととして\n",
    "# 三次元ベクトルについて勾配を使って最小値をもとめてみる\n",
    "\n",
    "import random\n",
    "from scratch.linear_algebra import distance, add, scalar_multiply\n",
    "\n",
    "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
    "    assert len(v) == len(gradient)\n",
    "    step = scalar_multiply(step_size, gradient)\n",
    "    return add(v, step)\n",
    "\n",
    "def sum_of_squares_gradient(v: Vector) -> Vector:\n",
    "    return [2 * v_i for v_i in v]\n",
    "\n",
    "# -10から１０の範囲でのランダムな３次元の開始点のベクトルを生成する\n",
    "v = [random.uniform(-10, 10) for i in range(3)]\n",
    "\n",
    "for epoch in range(1000):\n",
    "    grad = sum_of_squares_gradient(v)\n",
    "    v = gradient_step(v, grad, -0.01)\n",
    "    #print(epoch, v)\n",
    "    \n",
    "assert distance(v, [0,0, 0]) < 0.001\n",
    "\n",
    "# このコードを実行すると常にvが本来自明の[0, 0, 0]に非常に近い値で終了することがわかる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 最善の移動量を選択する\n",
    "\n",
    "勾配方向の移動について、最善の移動量選択の方法は移動時に目的関数が最小となるような移動量を決めるのが最善のように思えるが、実際は計算量を考え単純化して固定の移動量を使用することが多い"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 勾配降下法を使用してモデルを適合させる\n",
    "\n",
    "公開降下法を使用してパラメータ化されたモデルをデータに適合させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インプットxの範囲は-50から４９、yは２０ * x +5の線形関係\n",
    "inputs = [(x, 20 * x +5) for x in range(-50, 50)]\n",
    "\n",
    "# データから学習してxとyの線形関係のパラメータを見つける\n",
    "# 単一のデータポイントに対して gradの1番目の項目は勾配のわずかな増加により予測も増加。\n",
    "# ただしxが負の場合は予測は小さくなる\n",
    "# 2番目のgradの項目は切片のわずかな増加で予測を大きくする\n",
    "def linear_gradient(x: float, y: float, theta: Vector) -> Vector:\n",
    "    slope, intercept = theta\n",
    "    predicted = slope * x + intercept\n",
    "    error = (predicted -y)\n",
    "    squared_error = error ** 2\n",
    "    grad = [2 * error * x, 2 * error]\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット全体に対しては平均二乗誤差を調べる。\n",
    "# （予測値と誤差の平均値である平均二乗誤差は線形回帰モデルの性能を数値化する良い手段）\n",
    "# ランダムなtheta: Vectorを開始点とし、勾配を計算して勾配の方向にしたがってthetaを調整する\n",
    "\n",
    "from scratch.linear_algebra import vector_mean\n",
    "\n",
    "# ランダムな傾きと切片でスタートする\n",
    "theta = [random.uniform(-1, 1), random.uniform(-1,1)]\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 平均二乗距離をランダムなベクトルとinputsの実測値で算出し\n",
    "# learning_rateをステップのサイズとして、gradient_step()で\n",
    "# 勾配をより小さい方向に傾きと切片を設定しなおす（感じ？）\n",
    "for epoch in range(2500):\n",
    "    grad = vector_mean([linear_gradient(x, y, theta) for x,y in inputs])\n",
    "    theta = gradient_step(theta, grad, -learning_rate)\n",
    "    #print(epoch, theta)\n",
    "    \n",
    "slope, intercept = theta\n",
    "assert 19.9 < slope < 20.1\n",
    "assert 4.9 < intercept < 5.1\n",
    "\n",
    "# 2500エポックぐらいで\n",
    "# 傾きおおよそ２０、切片おおよそ５に収まる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.6 ミニバッチと確率的勾配降下法\n",
    "\n",
    "- 8.5の勾配降下法の欠点はパラメータを更新する前にデータセット全体の勾配を評価する必要があったこと\n",
    "- ミニバッチ勾配降下法は大きなデータセットからサンプリングした「ミニバッチ」に基づいた勾配の計算を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c2f041803ff1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mslope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0;36m19.9\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mslope\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m20.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;36m4.9\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mintercept\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m5.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# 勾配降下法では200~2500エポックぐらいで上記の範囲に傾きと切片の値が収まったが\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from typing import TypeVar, List, Iterator\n",
    "\n",
    "# TypeVarは\"Generics\"（具体的な型に依存しない抽象的かつ汎用的な関数クラス）として有効な型を宣言する？？\n",
    "# 下記ではTypeVarでTとい名前の型を宣言している\n",
    "T = TypeVar('T')\n",
    "\n",
    "def minibatches(dataset: List[T],\n",
    "               batch_size: int,\n",
    "               shuffle: bool = True) -> Iterator[List[T]]:\n",
    "    batch_starts = [start for start in range(0, len(dataset), batch_size)]\n",
    "    # リストbatch_starsの並び順をランダムにシャッフルする\n",
    "    if shuffle:  random.shuffle(batch_starts)\n",
    "    for start in batch_starts:\n",
    "        end = start + batch_size\n",
    "        yield dataset[start:end]\n",
    "        \n",
    "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for batch in minibatches(inputs, batch_size=20):\n",
    "        grad = vector_mean([linear_gradient(x, y, theta) for x, y in batch])\n",
    "        theta = gradient_step(theta, grad, -learning_rate)\n",
    "    #print(epoch, theta)\n",
    "    \n",
    "slope, intercept = theta\n",
    "assert 19.9 < slope < 20.1\n",
    "assert 4.9 < intercept < 5.1\n",
    "\n",
    "# 勾配降下法では200~2500エポックぐらいで上記の範囲に傾きと切片の値が収まったが\n",
    "# minibatchだとより少ないエポックで良い雰囲気"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確率的勾配降下法\n",
    "\n",
    "theta = [random.uniform(-1,1), random.uniform(-1, 1)]\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x, y in inputs:\n",
    "        grad = linear_gradient(x, y, theta)\n",
    "        theta = gradient_step(theta, grad, -learning_rate)\n",
    "    #print(epoch, theta)\n",
    "    \n",
    "slope, intercept = theta\n",
    "assert 19.9 < slope < 20.1\n",
    "assert 4.9 < intercept < 5.1\n",
    "\n",
    "# 一度に１つの学習に基づいて勾配ステップを実行すると\n",
    "# より少ないエポック数で最適なパラメータが見つかる、、、らしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
