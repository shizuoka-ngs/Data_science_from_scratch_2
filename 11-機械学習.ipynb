{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11章　機械学習\n",
    "\n",
    "## 11.1 モデリング\n",
    "\n",
    "- モデリングとは変数間の数学的or確率的関係の仕様\n",
    "- ビジネスモデル、料理のレシピなどもモデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 11.2 機械学習とは？\n",
    " \n",
    "- データからモデルを作成することとその活用を機械学習と本書では呼ぶ（定義は人それぞれだが）\n",
    "- 機械学習の目的は、メールのスパム予測、カードの不正使用の予測、広告のクリック率の予測、スポーツの勝敗の予測、、など\n",
    "- 本書ではデータに正解ラベルが添えられ__教師あり学習モデル__と、ラベルの存在しない__教師なし学習モデル__の両方を扱う（強化学習のようなどちらにも属さないモデルもあるが扱わない）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 過学習と未学習\n",
    "\n",
    "- 機械学習を行う上で注意しなければならない点の１つが、学習に使ったデータには高く適合するがその他のデータには適合しない汎用性の低いもd流ができてしまうこと=__過学習（Overfitting）__\n",
    "- 学習に使ったデータにさえモデルが上手く適合しない__未学習(Underfitting)__も注意すべきことの１つ\n",
    "- 図11.1は未学習な定数と、学習データによくフィットした（しかしおそらく汎用性の低い）９次多項式の例。一次多項式がよりフィットする可能性が高い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用とテスト用でデータを分割\n",
    "# TypeVarはジェネリクスの型変数を定義するための汎用的な型ヒント、、とのこと\n",
    "# コンテナ内のオブジェクトの型情報を明示できる（さらにわからないが、、）\n",
    "\n",
    "import random\n",
    "from typing import TypeVar, List, Tuple\n",
    "X = TypeVar('X')\n",
    "\n",
    "# データ分割器。TypeVarを使った型ヒントにこだわる理由はよくわからない\n",
    "# 順番をシャッフルし、cutまでとcut以後を返す\n",
    "def  split_data(data: List[X],  prob: float) -> Tuple[List[X], List[X]]:\n",
    "        data = data[:]\n",
    "        random.shuffle(data)\n",
    "        cut = int(len(data) * prob)\n",
    "        return data[:cut], data[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1000件でテスト\n",
    "data = [n for n in range(1000)]\n",
    "train, test = split_data(data, 0.75)\n",
    "\n",
    "# 1000件がこの比で分割されるはず\n",
    "assert len(train)  == 750\n",
    "assert len(test) == 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力変数と出力変数のペアを想定すると\n",
    "\n",
    "Y = TypeVar('Y') \n",
    "\n",
    "def train_test_split(xs: List[X], ys: List[Y], test_pct: float) -> Tuple[List[X], List[X], List[Y], List[Y]]:\n",
    "            idxs = [i for i in range(len(xs))]\n",
    "            train_idxs, test_idxs = split_data(idxs, 1 - test_pct)\n",
    "            return ([xs[i] for i in train_idxs],\n",
    "                    [xs[i] for i in test_idxs],\n",
    "                    [ys[i] for i in train_idxs],\n",
    "                    [ys[i] for i in test_idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [x for x in range(1000)]\n",
    "ys = [2 * x for x in xs]\n",
    "x_train, y_test, y_train, y_test = train_test_split(xs, ys, 0.33)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4 正確さ\n",
    "\n",
    "- 二項分類の予測モデルに対するラベル付きデータは以下の4カテゴリに属する\n",
    "    - 真陽性\n",
    "    - 偽陽性\n",
    "    - 偽陰性\n",
    "    - 真陰性\n",
    "    \n",
    "### 混同行列\n",
    "\n",
    "**二項分類した４つのカテゴリは混同行列として表現することができる**\n",
    "\n",
    "\n",
    "|   | スパム | スパムで無い |\n",
    "|:-----------|------------:|:------------:|\n",
    "| スパムと判断       | 真陽性        | 偽陽性         |\n",
    "| スパムでは無いと判断     | 偽陰性      | 真陰性\n",
    "\n",
    "\n",
    "### 「ルークが白血病になる」テストの混同行列\n",
    "\n",
    "- 1,000人あたり5人の新生児がルークとなづけられる\n",
    "- 白血病の患者数は1.4%\n",
    "\n",
    "これらの値が独立である場合「ルークが白血病になる」テスト100万人の混同行列は\n",
    "\n",
    "|   | 白血病である | 白血病でない | 合計 |\n",
    "|:-----------|------------:|:------------:|:----------:|\n",
    "| ルークである       | 70        | 4930  |   5,000    |\n",
    "| ルークでは無い     | 13930      | 891070　| 995,000 |\n",
    "| 合計   |  14,000 | 896,000 | 1,000,000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正しい予測結果の割合\n",
    "# 正解率は\n",
    "# correct: 真陽性 + 真陰性 トータルデータ数で割った値として返す\n",
    "\n",
    "def accuracy(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    correct = tp +tn\n",
    "    total = tp + fp + fn + tn\n",
    "    return correct /total\n",
    "\n",
    "assert accuracy(70, 4930, 13930, 981070) == 0.98114"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 上の正解率は興味深い結果（これだけみるとモデルが確からしく思える）\n",
    "\n",
    "- ただし正解率がそまままがモデルのただしさの証拠にならない\n",
    "- **適合率(precision)**と**再現率（recall）**の組み合わせをみるのが常套手段\n",
    "\n",
    "この例のように、適合率と再現率のどの値も小さいのはモデルがよく無いことを示す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 適合率を 真陽性/(真陽性+偽陽性)　で得る\n",
    "\n",
    "def precision(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp /(tp + fp)\n",
    "\n",
    "assert precision(70, 4930, 13930, 981070) == 0.014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再現率を 真陽性/(真陽性＋偽陰性)で得る\n",
    "\n",
    "def recall(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "assert recall(70, 4930, 13930, 981070)  == 0.005 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- F1値は適合率と再現率の調和平均（ただ適切なトレードオフ？がこの関数にどう関連づくのはよくわからない。。。）\n",
    "- モデルの選択は適合率と再現率のトレードオフを伴う（偽陽性と偽陰性のトレードオフ）\n",
    "- 域値を上げれば適合率を上がる（ex.多くの危険因子を持つ程発症の可能性が上がる等）が再現率は下がる（域値に適合する患者の数は少なくなる）\n",
    "- このように適切な域値を設定することで、適切なトレードオフをみつけることになる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00736842105263158"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 適合率と再現率の調和平均\n",
    "# ただ適切なトレードオフとは？をこの関数にどう関連づくのはよくわからない。。。\n",
    "\n",
    "def f1_score(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "    return 2 * p *r / (p + r)\n",
    "\n",
    "f1_score(70, 4930, 13930, 981070) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5 バイアス-バリアント　トレードオフ\n",
    "\n",
    "- バイアス、バリアントはどちらも学習を異なるデータで何度も行なった場合の振る舞いを評価するもの\n",
    "- 過学習の問題は、バイアスとバリアンスのトレードオフとして考えることができる\n",
    "- 無作為に抽出した２つの学習用データおはおおよそ同じような平均値を持ち、低いバリアンスを示すと言える\n",
    "- 高いバイアスと低いバリアンスはだいたい未学習に相当する\n",
    "- 9次多項式のモデルのような低いバイアス、高いバリアンスは過学習に相当する\n",
    "- モデルが高いバイアスを持つ場合は別の特徴を考える\n",
    "- 高いバリアンスを持つ場合は特徴を除くこと、より多くの学習データを投入することを考える\n",
    "\n",
    "※重要な用語と思うのだがバイアス・バリアントの概念が上手くイメージできない。。。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6 特徴抽出と特徴選択\n",
    "\n",
    "- 特徴とは：モデルに対するあらゆる入力に相当する\n",
    "- データに十分な特徴がなければモデルが未学習になる傾向にあり、多くの特徴があると過学習になりがち\n",
    "- 特徴はYes/No(1or 0), 数値、個別の選択肢から概ねえらぶことになる（スパムメールフィルターを考えた場合）\n",
    "- どのような種類の特徴を使うかは、どのようなモデルを使うに依存する（※使うモデルに依存するというところに留意）\n",
    "    - ベイズ分類機はYes/No型\n",
    "    - 回帰モデルは数値（0/1を含む）\n",
    "    - 決定木は数値または分類されたデータ\n",
    "- 何百個もの数値で構成されるベクトルがあるとしたら、場合により次元圧縮のような次元を絞り少数の特徴を扱うことが適切\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
